# -*- coding: utf-8 -*-
"""project2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-LiGiZM0tODiNm7Qx-YvgyxyzZvQfVwm
"""

# importing basic labraries for case study

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import sklearn 
import seaborn as sns

#reading data for case study

dfMovies = pd.read_csv("movies.dat",sep="::",names=["MovieID","Title","Genres"],engine='python')

dfMovies

dfMovies.shape

dfMovies.isnull().sum()

dfratings=pd.read_csv('ratings.dat',sep="::",names=['UserID','MovieID','Rating','Timestamp'])

dfratings.head()

dfratings.shape

dfratings.isnull().sum()

dfuser=pd.read_csv('users.dat',sep="::",names=['UserID','Gender','Age','Occupation','Zip-code'])

dfuser.head()

dfuser.shape

dfuser.isnull().sum()

dfMovies.columns

dfratings.columns

dfuser.columns

dfuser.info()

# geting master data from all three files
#extraction data information master data

final_mas=dfMovies.merge(dfratings,how='left',left_on='MovieID',right_on='MovieID')

final_mas.info()

master_data=final_mas.merge(dfuser,how='left',left_on='UserID',right_on='UserID')

master_data.drop(labels=['Timestamp','Zip-code'],axis=1,inplace=True)

master_data.head()

# Age distribution in dataset 
# plot of age distribution

master_data.Age.value_counts()

age_dist=master_data.groupby('Age').size()

plt.hist(data=age_dist,x=[master_data.Age],bins=30)
plt.show()

"""### most of the viewers for the movies lies between 20 year to 35 years """

A= master_data.Rating.groupby(master_data.Title=='Toy story (1995)').size()

A

plt.hist(data=A,x=[master_data.Rating],bins=30)
plt.show()

"""### maximum viewer gives rating to toy story (1995) ,3 to 5 """

##top 25 movie by ratings

A1=master_data.groupby('MovieID').agg({'Rating':'mean'})

A1.sort_values('Rating',ascending=False).head(25)

"""# part 2
###Find out all the unique genres.
"""

master_data.columns

C=list(master_data.Genres.str.split('|').values)

uniquegerne= set()
for i in C:
    uniquegerne=uniquegerne.union(set(i))
uniquegerne

uniquegerne1=list(uniquegerne)

# apply label encoding and one-hot encoding on cattegorical data

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from numpy import array
#uniquegerne1=array(uniquegerne1)
labelencode= LabelEncoder()
intdata=labelencode.fit_transform(uniquegerne1)
intdata=intdata.reshape(len(intdata),1)

intdata

onhot_encode=OneHotEncoder(sparse=False)
onehot=onhot_encode.fit_transform(intdata)
print(onehot)

"""### fetures data which most affecting to target(rating )"""

data=master_data[:500]

data.head()

feture_col=['MovieID','Age','Occupation']

"""# model building"""

x=data[feture_col]

y=data[['Rating']].values

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33)

x_test.shape

x_train.shape

y_train.shape

y_test.shape

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

# knn classifire 
# K Nearest Neighbors Classifier

knn = KNeighborsClassifier(n_neighbors = 3)
knn.fit(x_train,y_train)
Y_pred = knn.predict(x_test)

#Evaluate the accuracy of  model
from sklearn import metrics
x= metrics.accuracy_score(y_test,Y_pred)
print(x)

#logistic model
logis=LogisticRegression()
logis.fit(x_train,y_train)
y_pred=logis.predict(x_test)

#Evaluate the accuracy of  model
from sklearn import metrics
x= metrics.accuracy_score(y_test,y_pred)
print(x)

#random forest
random_forest = RandomForestClassifier(n_estimators=100)
random_forest.fit(x_train, y_train)
y_pred = random_forest.predict(x_test)
random_forest.score(x_train,y_train)
acc_random_forest = round(random_forest.score(x_train, y_train) * 100, 2)
acc_random_forest

#Evaluate the accuracy of  model
from sklearn import metrics
x= metrics.accuracy_score(y_test,y_pred)
print(x)



